{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "7rkrcgOoGafa"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression Assignment"
      ],
      "metadata": {
        "id": "7rkrcgOoGafa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. What is Logistic Regression, and how does it differ from Linear Regression?\n",
        "‚úçÔ∏è Answer:\n",
        "Logistic Regression is a classification algorithm used to predict binary outcomes (like Yes/No or 0/1). It models the probability that an instance belongs to a particular class.\n",
        "Linear Regression predicts continuous numerical values, whereas Logistic Regression predicts probabilities for classification."
      ],
      "metadata": {
        "id": "2yB80VryGchN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. What is the mathematical equation of Logistic Regression?\n",
        "‚úçÔ∏è Answer:\n",
        "\n",
        "P(Y=1|X) = 1/1+e^-(b0+b1x1+...bnxn)"
      ],
      "metadata": {
        "id": "BMI4Ac3OGcsl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Why do we use the Sigmoid function in Logistic Regression?\n",
        "‚úçÔ∏è Answer:\n",
        "The Sigmoid function maps predicted values to a range between 0 and 1, representing probabilities. It helps in interpreting the output as the probability of belonging to the positive class."
      ],
      "metadata": {
        "id": "LnKjsfbBGc67"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. What is the cost function of Logistic Regression?\n",
        "‚úçÔ∏è Answer:\n",
        "Logistic Regression uses Binary Cross-Entropy Loss (also called Log Loss):\n",
        "\n",
        "ùê∂\n",
        "ùëú\n",
        "ùë†\n",
        "ùë°\n",
        "=\n",
        "‚àí\n",
        "1/\n",
        "ùëõ\n",
        "‚àë\n",
        "[\n",
        "ùë¶\n",
        "ùëñ\n",
        "log\n",
        "‚Å°\n",
        "(\n",
        "ùë¶\n",
        "ùëñ\n",
        "^\n",
        ")\n",
        "+\n",
        "(\n",
        "1\n",
        "‚àí\n",
        "ùëñ\n",
        ")\n",
        "log\n",
        "‚Å°\n",
        "(\n",
        "1\n",
        "‚àí\n",
        "ùë¶\n",
        "ùëñ\n",
        "^\n",
        ")\n",
        "]\n"
      ],
      "metadata": {
        "id": "3AXrQmv8GdKQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. What is Regularization in Logistic Regression? Why is it needed?\n",
        "‚úçÔ∏è Answer:\n",
        "Regularization adds a penalty term to the cost function to prevent overfitting by discouraging overly complex models.\n",
        "It keeps model coefficients small and improves generalization."
      ],
      "metadata": {
        "id": "jEEu4BeOGdWP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Explain the difference between Lasso, Ridge, and Elastic Net regression\n",
        "‚úçÔ∏è Answer:\n",
        "\n",
        "Lasso (L1): Can shrink some coefficients to exactly zero (feature selection).\n",
        "\n",
        "Ridge (L2): Shrinks coefficients but doesn‚Äôt set any to zero.\n",
        "\n",
        "Elastic Net: Combination of L1 and L2, balancing between shrinkage and feature selection."
      ],
      "metadata": {
        "id": "gpAXSj2MGdge"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. When should we use Elastic Net instead of Lasso or Ridge?\n",
        "‚úçÔ∏è Answer:\n",
        "Use Elastic Net when there are many correlated features because it balances both Lasso (feature selection) and Ridge (coefficient shrinkage)."
      ],
      "metadata": {
        "id": "sK8OY1CtGdqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. What is the impact of the regularization parameter (Œª) in Logistic Regression?\n",
        "‚úçÔ∏è Answer:\n",
        "\n",
        "Higher Œª ‚Üí More regularization ‚Üí Simpler model, may underfit.\n",
        "\n",
        "Lower Œª ‚Üí Less regularization ‚Üí More complex model, may overfit."
      ],
      "metadata": {
        "id": "Panw1W9tGdzp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. What are the key assumptions of Logistic Regression?\n",
        "‚úçÔ∏è Answer:\n",
        "\n",
        "No multicollinearity among independent variables\n",
        "\n",
        "Large sample size\n",
        "\n",
        "Linearity between independent variables and log-odds\n",
        "\n",
        "Independent observations"
      ],
      "metadata": {
        "id": "DjJFv-dEGd-Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. What are some alternatives to Logistic Regression for classification tasks?\n",
        "‚úçÔ∏è Answer:\n",
        "\n",
        "Decision Trees\n",
        "\n",
        "Random Forest\n",
        "\n",
        "Support Vector Machines (SVM)\n",
        "\n",
        "k-Nearest Neighbors (k-NN)\n",
        "\n",
        "Neural Networks"
      ],
      "metadata": {
        "id": "4mCU-MSgGeH_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. What are Classification Evaluation Metrics?\n",
        "‚úçÔ∏è Answer:\n",
        "\n",
        "Accuracy\n",
        "\n",
        "Precision\n",
        "\n",
        "Recall\n",
        "\n",
        "F1-Score\n",
        "\n",
        "ROC-AUC\n",
        "\n",
        "Confusion Matrix"
      ],
      "metadata": {
        "id": "niz_BnniGeSc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "12. How does class imbalance affect Logistic Regression?\n",
        "‚úçÔ∏è Answer:\n",
        "When classes are imbalanced, the model may be biased towards the majority class, leading to poor performance on minority classes.\n",
        "Solutions include resampling techniques or using class weights."
      ],
      "metadata": {
        "id": "gz9DOcM5Gebf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "13. What is Hyperparameter Tuning in Logistic Regression?\n",
        "‚úçÔ∏è Answer:\n",
        "Hyperparameter tuning involves finding the best set of parameters (like C, penalty, solver) that optimize model performance using techniques like GridSearchCV or RandomizedSearchCV.\n",
        "\n"
      ],
      "metadata": {
        "id": "NwXx5l9FGeld"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "14. What are different solvers in Logistic Regression? Which one should be used?\n",
        "‚úçÔ∏è Answer:\n",
        "\n",
        "liblinear: Good for small datasets, supports L1 and L2 regularization.\n",
        "\n",
        "lbfgs: Good for multiclass and large datasets.\n",
        "\n",
        "saga: Handles L1, L2, Elastic Net; good for large datasets.\n",
        "Choose solver based on dataset size and regularization needs.\n",
        "\n"
      ],
      "metadata": {
        "id": "TUXg3IsMGevF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "15. How is Logistic Regression extended for multiclass classification?\n",
        "‚úçÔ∏è Answer:\n",
        "\n",
        "One-vs-Rest (OvR): Build one binary classifier per class.\n",
        "\n",
        "Softmax Regression: Generalization for multiple classes at once."
      ],
      "metadata": {
        "id": "ildSsrcaGe4t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "16. What are the advantages and disadvantages of Logistic Regression?\n",
        "‚úçÔ∏è Answer:\n",
        "Advantages:\n",
        "\n",
        "Simple and easy to implement\n",
        "\n",
        "Outputs probabilities\n",
        "\n",
        "Works well with linearly separable data\n",
        "\n",
        "Disadvantages:\n",
        "\n",
        "Struggles with non-linear relationships\n",
        "\n",
        "Assumes linear decision boundary"
      ],
      "metadata": {
        "id": "EmSC8NIeGfB9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "17. What are some use cases of Logistic Regression?\n",
        "‚úçÔ∏è Answer:\n",
        "\n",
        "Spam email detection\n",
        "\n",
        "Customer churn prediction\n",
        "\n",
        "Disease diagnosis (yes/no)\n",
        "\n",
        "Credit card fraud detection\n",
        "\n"
      ],
      "metadata": {
        "id": "qtmgElgAGfKm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "18. What is the difference between Softmax Regression and Logistic Regression?\n",
        "‚úçÔ∏è Answer:\n",
        "\n",
        "Logistic Regression handles binary classification.\n",
        "\n",
        "Softmax Regression handles multiclass classification by assigning probabilities across multiple classes.\n",
        "\n"
      ],
      "metadata": {
        "id": "fVnJ2_iOGfUE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "19. How do we choose between One-vs-Rest (OvR) and Softmax for multiclass classification?\n",
        "‚úçÔ∏è Answer:\n",
        "\n",
        "Use OvR for simple, smaller datasets where binary classifiers are efficient.\n",
        "\n",
        "Use Softmax for large, complex multiclass problems needing probability distribution across classes."
      ],
      "metadata": {
        "id": "nzgTFM5ZGfdV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "20. How do we interpret coefficients in Logistic Regression?\n",
        "‚úçÔ∏è Answer:\n",
        "The coefficients represent the change in the log-odds of the outcome for a one-unit increase in the predictor variable, holding other variables constant."
      ],
      "metadata": {
        "id": "HgSV365HGfmj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression Practical"
      ],
      "metadata": {
        "id": "344lt8JqGfxH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Write a Python program that loads a dataset, splits it into training and testing sets,\n",
        "# applies Logistic Regression, and prints the model accuracy.\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Convert to binary classification\n",
        "y_binary = (y == 0).astype(int)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_binary, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Logistic Regression\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkz5Q5AuI1xy",
        "outputId": "71ec5834-dd87-4497-9f70-9027b36b07da"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Write a Python program to apply L1 regularization (Lasso) on a dataset\n",
        "# using LogisticRegression(penalty='l1') and print the model accuracy.\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "y_binary = (y == 0).astype(int)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_binary, test_size=0.3, random_state=42)\n",
        "\n",
        "model_l1 = LogisticRegression(penalty='l1', solver='liblinear')\n",
        "model_l1.fit(X_train, y_train)\n",
        "y_pred_l1 = model_l1.predict(X_test)\n",
        "\n",
        "print(\"L1 Regularized Accuracy:\", accuracy_score(y_test, y_pred_l1))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gV7msKitI1oI",
        "outputId": "86ee88b2-555c-4e1e-e470-e6a010144864"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L1 Regularized Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Write a Python program to train Logistic Regression with L2 regularization (Ridge)\n",
        "# using LogisticRegression(penalty='l2'). Print model accuracy and coefficients.\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "y_binary = (y == 0).astype(int)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_binary, test_size=0.3, random_state=42)\n",
        "\n",
        "model_l2 = LogisticRegression(penalty='l2')\n",
        "model_l2.fit(X_train, y_train)\n",
        "y_pred_l2 = model_l2.predict(X_test)\n",
        "\n",
        "print(\"L2 Regularized Accuracy:\", accuracy_score(y_test, y_pred_l2))\n",
        "print(\"Coefficients:\", model_l2.coef_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxzP-ejeI1ec",
        "outputId": "d7105b87-1c47-4f3d-a3c8-2ca981d76057"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L2 Regularized Accuracy: 1.0\n",
            "Coefficients: [[-0.43107698  0.84570847 -2.15658006 -0.88940818]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Write a Python program to train Logistic Regression with Elastic Net Regularization (penalty='elasticnet').\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "y_binary = (y == 0).astype(int)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_binary, test_size=0.3, random_state=42)\n",
        "\n",
        "model_elastic = LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.5)\n",
        "model_elastic.fit(X_train, y_train)\n",
        "y_pred_elastic = model_elastic.predict(X_test)\n",
        "\n",
        "print(\"Elastic Net Accuracy:\", accuracy_score(y_test, y_pred_elastic))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p10rPjhRI1U3",
        "outputId": "1de7f737-7d07-418c-a09c-139c5807f10d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elastic Net Accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Write a Python program to train a Logistic Regression model for multiclass classification using multi_class='ovr'.\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "model_multiclass = LogisticRegression(multi_class='ovr')\n",
        "model_multiclass.fit(X_train, y_train)\n",
        "y_pred_multiclass = model_multiclass.predict(X_test)\n",
        "\n",
        "print(\"Multiclass (OvR) Accuracy:\", accuracy_score(y_test, y_pred_multiclass))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXvW9VOdI1NB",
        "outputId": "9fe25f4d-24e5-453e-b70c-013102df0c5b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Multiclass (OvR) Accuracy: 0.9555555555555556\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Write a Python program to apply GridSearchCV to tune the hyperparameters (C and penalty) of Logistic Regression.\n",
        "# Print the best parameters and accuracy.\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "y_binary = (y == 0).astype(int)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_binary, test_size=0.3, random_state=42)\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10],\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'solver': ['liblinear']\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(LogisticRegression(), param_grid, cv=5)\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best Parameters:\", grid.best_params_)\n",
        "print(\"Best Accuracy on Validation:\", grid.best_score_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JroSCT18I1Cx",
        "outputId": "53f3aa48-0887-4e49-aceb-6f68b59c59fd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "Best Accuracy on Validation: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Write a Python program to evaluate Logistic Regression using Stratified K-Fold Cross-Validation.\n",
        "# Print the average accuracy.\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "y_binary = (y == 0).astype(int)\n",
        "\n",
        "model_skf = LogisticRegression()\n",
        "skf = StratifiedKFold(n_splits=5)\n",
        "\n",
        "scores = cross_val_score(model_skf, X, y_binary, cv=skf)\n",
        "\n",
        "print(\"Cross-Validation Scores:\", scores)\n",
        "print(\"Average Accuracy:\", scores.mean())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9d5deJbaI057",
        "outputId": "31af165b-6932-4f9a-8a22-7967d81f0f1d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-Validation Scores: [1. 1. 1. 1. 1.]\n",
            "Average Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. Write a Python program to load a dataset from a CSV file,\n",
        "# apply Logistic Regression, and evaluate its accuracy.\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Simulating a CSV using Iris data\n",
        "data = load_iris()\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "df['target'] = (data.target == 0).astype(int)\n",
        "\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(\"CSV Dataset Accuracy:\", model.score(X_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ajD5LQYKI0w7",
        "outputId": "ab5d27c3-7830-4c43-e0c5-be481465592c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV Dataset Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. Write a Python program to apply RandomizedSearchCV for tuning hyperparameters (C, penalty, solver)\n",
        "# in Logistic Regression. Print the best parameters and accuracy.\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import scipy.stats as stats\n",
        "\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "y_binary = (y == 0).astype(int)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_binary, test_size=0.3, random_state=42)\n",
        "\n",
        "param_dist = {\n",
        "    'C': stats.uniform(0.01, 10),\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'solver': ['liblinear', 'saga']\n",
        "}\n",
        "\n",
        "random_search = RandomizedSearchCV(LogisticRegression(), param_distributions=param_dist, n_iter=10, cv=5, random_state=42)\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best Parameters:\", random_search.best_params_)\n",
        "print(\"Best Accuracy on Validation:\", random_search.best_score_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UolxWrBLKGgI",
        "outputId": "3a4b2b3c-1f0b-4f69-a66e-be82b3cfc264"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'C': np.float64(3.7554011884736247), 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "Best Accuracy on Validation: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 10. Write a Python program to implement One-vs-One (OvO) Multiclass Logistic Regression\n",
        "# and print accuracy.\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.multiclass import OneVsOneClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "ovo_model = OneVsOneClassifier(LogisticRegression())\n",
        "ovo_model.fit(X_train, y_train)\n",
        "\n",
        "y_pred_ovo = ovo_model.predict(X_test)\n",
        "\n",
        "print(\"One-vs-One (OvO) Multiclass Accuracy:\", accuracy_score(y_test, y_pred_ovo))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7mIn-JEI0nh",
        "outputId": "5abdf50d-da2c-4a42-b854-0ffb86cdf4c5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "One-vs-One (OvO) Multiclass Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 11. Write a Python program to train a Logistic Regression model and visualize the confusion matrix for binary classification.\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "y_binary = (y == 0).astype(int)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_binary, test_size=0.3, random_state=42)\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "disp.plot()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "dVicyr1mI0fi",
        "outputId": "63489abe-d064-46bb-8187-b8942c29085e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 12. Write a Python program to train a Logistic Regression model and evaluate its performance using Precision, Recall, and F1-Score.\n",
        "\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-Score:\", f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-riXpdYsI0We",
        "outputId": "d43e651f-839d-4c1c-9bca-ada3a509fe03"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1-Score: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 13. Write a Python program to train a Logistic Regression model on imbalanced data and apply class weights to improve model performance.\n",
        "\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "X, y = make_classification(n_classes=2, class_sep=2, weights=[0.9, 0.1], n_informative=3, n_redundant=0, flip_y=0, n_features=5, n_clusters_per_class=1, n_samples=1000, random_state=42)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "model_weighted = LogisticRegression(class_weight='balanced')\n",
        "model_weighted.fit(X_train, y_train)\n",
        "y_pred_weighted = model_weighted.predict(X_test)\n",
        "\n",
        "print(\"Accuracy with class weights:\", accuracy_score(y_test, y_pred_weighted))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QsUcshFDI0N4",
        "outputId": "8dff1688-1117-4bac-8148-d0f5f3e7e8bc"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with class weights: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 14. Write a Python program to train Logistic Regression on the Titanic dataset, handle missing values, and evaluate performance.\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load Titanic dataset\n",
        "url = 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv'\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# Feature selection and preprocessing\n",
        "df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
        "df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)\n",
        "\n",
        "df = df.drop(['Name', 'Ticket', 'Cabin', 'PassengerId'], axis=1)\n",
        "df = pd.get_dummies(df, drop_first=True)\n",
        "\n",
        "X = df.drop('Survived', axis=1)\n",
        "y = df['Survived']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(\"Titanic Dataset Accuracy:\", model.score(X_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxU7DSARI0De",
        "outputId": "6ff5ac2a-a88b-4814-d497-8e504171d84c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Titanic Dataset Accuracy: 0.8097014925373134\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-d11f058cd298>:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
            "<ipython-input-14-d11f058cd298>:14: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 15. Write a Python program to apply feature scaling (Standardization) before training a Logistic Regression model.\n",
        "# Evaluate its accuracy and compare results with and without scaling.\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Without scaling\n",
        "model_no_scaling = LogisticRegression(max_iter=1000)\n",
        "model_no_scaling.fit(X_train, y_train)\n",
        "acc_no_scaling = model_no_scaling.score(X_test, y_test)\n",
        "\n",
        "# With scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "model_scaling = LogisticRegression(max_iter=1000)\n",
        "model_scaling.fit(X_train_scaled, y_train)\n",
        "acc_scaling = model_scaling.score(X_test_scaled, y_test)\n",
        "\n",
        "print(\"Accuracy without scaling:\", acc_no_scaling)\n",
        "print(\"Accuracy with scaling:\", acc_scaling)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-oSUtfQPIz6o",
        "outputId": "32e318cc-5c92-4802-f0c5-208230664517"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy without scaling: 0.8097014925373134\n",
            "Accuracy with scaling: 0.8097014925373134\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 16. Write a Python program to train Logistic Regression and evaluate its performance using ROC-AUC score.\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "y_pred_prob = model.predict_proba(X_test)[:, 1]\n",
        "roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
        "\n",
        "print(\"ROC-AUC Score:\", roc_auc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZRd2t5NIzy4",
        "outputId": "8844e990-aa10-437d-9691-4e1a62dc85e5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC-AUC Score: 0.8804728295174155\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 17. Write a Python program to train Logistic Regression using a custom learning rate (C=0.5) and evaluate accuracy.\n",
        "\n",
        "model_cust = LogisticRegression(C=0.5)\n",
        "model_cust.fit(X_train, y_train)\n",
        "print(\"Accuracy with C=0.5:\", model_cust.score(X_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkM9OWdoIzqI",
        "outputId": "49ade761-44fc-427d-ab98-e0cfdc4803db"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with C=0.5: 0.8134328358208955\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 18. Write a Python program to train Logistic Regression and identify important features based on model coefficients.\n",
        "\n",
        "feature_importance = pd.Series(model_cust.coef_[0], index=X.columns)\n",
        "print(\"Feature Importance:\")\n",
        "print(feature_importance.sort_values(ascending=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrJJsbHuIzhk",
        "outputId": "e4d43a92-ccf0-47c4-83af-9752463be603"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Importance:\n",
            "Embarked_Q    0.040949\n",
            "Fare          0.003687\n",
            "Age          -0.033011\n",
            "Parch        -0.114121\n",
            "SibSp        -0.294912\n",
            "Embarked_S   -0.492176\n",
            "Pclass       -0.910377\n",
            "Sex_male     -2.291907\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 19. Write a Python program to train Logistic Regression and evaluate its performance using Cohen‚Äôs Kappa Score.\n",
        "\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "\n",
        "y_pred_cust = model_cust.predict(X_test)\n",
        "kappa = cohen_kappa_score(y_test, y_pred_cust)\n",
        "\n",
        "print(\"Cohen's Kappa Score:\", kappa)\n"
      ],
      "metadata": {
        "id": "ZoqABLiCIzZV"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 20. Write a Python program to train Logistic Regression and visualize the Precision-Recall Curve for binary classification.\n",
        "\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "precision, recall, thresholds = precision_recall_curve(y_test, y_pred_prob)\n",
        "\n",
        "plt.plot(recall, precision, marker='.')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "t5fZgM2tIzQZ",
        "outputId": "59872908-433a-4ccc-e028-2de69b4deca4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 21. Write a Python program to train Logistic Regression with different solvers (liblinear, saga, lbfgs) and compare their accuracy.\n",
        "\n",
        "solvers = ['liblinear', 'saga', 'lbfgs']\n",
        "\n",
        "for solver in solvers:\n",
        "    model_solver = LogisticRegression(solver=solver, max_iter=5000)\n",
        "    model_solver.fit(X_train, y_train)\n",
        "    acc_solver = model_solver.score(X_test, y_test)\n",
        "    print(f\"Solver: {solver} -> Accuracy: {acc_solver}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5d7xNUgkIzI5",
        "outputId": "2988ab2a-0f81-44ab-c74d-929e7a5d6407"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Solver: liblinear -> Accuracy: 0.8022388059701493\n",
            "Solver: saga -> Accuracy: 0.7910447761194029\n",
            "Solver: lbfgs -> Accuracy: 0.8097014925373134\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 22. Write a Python program to train Logistic Regression and evaluate its performance using Matthews Correlation Coefficient (MCC).\n",
        "\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "y_pred_solver = model.predict(X_test)\n",
        "mcc = matthews_corrcoef(y_test, y_pred_solver)\n",
        "\n",
        "print(\"Matthews Correlation Coefficient (MCC):\", mcc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOdGzTLsIzAF",
        "outputId": "287481ed-e982-47b3-ab67-1dbe867b5fdb"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matthews Correlation Coefficient (MCC): 0.604620506499641\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 23. Write a Python program to train Logistic Regression on both raw and standardized data.\n",
        "# Compare their accuracy to see the impact of feature scaling.\n",
        "\n",
        "# (Already covered earlier in scaling question - here summarize)\n",
        "\n",
        "print(\"Accuracy Comparison:\")\n",
        "print(f\"Without Scaling: {acc_no_scaling}\")\n",
        "print(f\"With Scaling: {acc_scaling}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GoDlPEc-Iy3D",
        "outputId": "599dda33-a81a-41d8-90c0-73d237202772"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Comparison:\n",
            "Without Scaling: 0.8097014925373134\n",
            "With Scaling: 0.8097014925373134\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 24. Write a Python program to train Logistic Regression and find the optimal C (regularization strength) using cross-validation.\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid_c = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
        "\n",
        "grid_c = GridSearchCV(LogisticRegression(max_iter=1000), param_grid_c, cv=5)\n",
        "grid_c.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best C value:\", grid_c.best_params_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ligPYIR5Iysq",
        "outputId": "6459ba43-b8a3-4cee-b0a8-2035612502a3"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best C value: {'C': 0.1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 25. Write a Python program to train Logistic Regression, save the trained model using joblib, and load it again to make predictions.\n",
        "\n",
        "import joblib\n",
        "\n",
        "# Train and save\n",
        "model_save = LogisticRegression(max_iter=1000)\n",
        "model_save.fit(X_train, y_train)\n",
        "joblib.dump(model_save, 'logistic_model.pkl')\n",
        "\n",
        "# Load and predict\n",
        "loaded_model = joblib.load('logistic_model.pkl')\n",
        "print(\"Loaded Model Accuracy:\", loaded_model.score(X_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TyYnU4k3Iyje",
        "outputId": "78e2092d-ab91-45b3-cd93-32fd7ed8d652"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded Model Accuracy: 0.8097014925373134\n"
          ]
        }
      ]
    }
  ]
}